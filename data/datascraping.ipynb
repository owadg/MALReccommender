{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "301bf995",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import scipy\n",
    "import scipy.optimize\n",
    "from sklearn import svm\n",
    "import numpy\n",
    "import string\n",
    "import random\n",
    "import string\n",
    "import json\n",
    "import time\n",
    "import requests\n",
    "import re\n",
    "from sklearn import linear_model\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31cab31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e25a33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readGz(path):\n",
    "    for l in gzip.open(path, 'rt'):\n",
    "        yield eval(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f88efc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readCSV(path):\n",
    "    f = gzip.open(path, 'rt')\n",
    "    f.readline()\n",
    "    for l in f:\n",
    "        u,b,r = l.strip().split(',')\n",
    "        r = int(r)\n",
    "        yield u,b,r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e50df1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get API KEY\n",
    "file = open(\"mal_client_id.txt\", 'r')\n",
    "clientID = file.read()\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1ca8c1f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have done 500 requests\n",
      "We have done 1000 requests\n",
      "We have done 1500 requests\n",
      "We have done 2000 requests\n",
      "We have done 2500 requests\n",
      "We have done 3000 requests\n",
      "We have done 3500 requests\n",
      "We have done 4000 requests\n",
      "We have done 4500 requests\n",
      "We have done 5000 requests\n",
      "We have done 5500 requests\n",
      "We have done 6000 requests\n",
      "We have done 6500 requests\n",
      "We have done 7000 requests\n",
      "We have done 7500 requests\n",
      "We have done 8000 requests\n",
      "We have done 8500 requests\n",
      "We have done 9000 requests\n",
      "We have done 9500 requests\n",
      "We have done 10000 requests\n",
      "We have done 10500 requests\n",
      "We have done 11000 requests\n",
      "We have done 11500 requests\n",
      "We have done 12000 requests\n",
      "We have done 12500 requests\n",
      "We have done 13000 requests\n",
      "We have done 13500 requests\n",
      "We have done 14000 requests\n",
      "We have done 14500 requests\n",
      "We have done 15000 requests\n"
     ]
    }
   ],
   "source": [
    "# let's generate a list of anime\n",
    "# Methodology\n",
    "# we generate according to the popularity list, rather than trolling through IDs, as not every ID is a valid entry.\n",
    "# this has the added benefit of being able to cull the absolute most useless ones. \n",
    "\n",
    "# data\n",
    "data = []\n",
    "\n",
    "# constants\n",
    "lowest_ranking_threshhold = 15000\n",
    "entries_per_page = 500\n",
    "fields = [\"id\", \"title\", \"start_date\", \"end_date\", \"mean\", \"rank\", \"popularity\", \"num_list_users\", \"num_scoring_users\", \"nsfw\", \"genres\", \"status\", \"num_episodes\", \"start_season\", \"broadcast\", \"average_episode_duration\", \"rating\", \"studios\"]\n",
    "questionableFields = [\"synopsis\"] #probably going to include this still\n",
    "apiURL = \"https://api.myanimelist.net/v2/anime/ranking?\"\n",
    "\n",
    "head = {\"X-MAL-CLIENT-ID\": clientID}\n",
    "par = {\"ranking_type\":\"all\", \n",
    "          \"fields\":\"id,title,start_date,end_date,mean,rank,popularity,num_list_users,num_scoring_users,synopsis,nsfw,genres,status,num_episodes,start_season,broadcast,average_episode_duration,rating,studios\", \n",
    "          \"limit\":entries_per_page,\n",
    "          \"offset\":0,\n",
    "}\n",
    "\n",
    "response = requests.get(apiURL, headers=head, params=par)\n",
    "infoArray = response.json()['data']\n",
    "for i in infoArray:\n",
    "    data.append(i['node'])\n",
    "nextPage = response.json()['paging']['next']\n",
    "\n",
    "#tentatively grabbing first 15000 anime, 500 at a time\n",
    "for j in range(lowest_ranking_threshhold//entries_per_page):\n",
    "    #getting data\n",
    "    response = requests.get(nextPage, headers=head)\n",
    "    infoArray = response.json()['data']\n",
    "    for i in infoArray:\n",
    "        data.append(i['node'])\n",
    "    \n",
    "    #now let's get the next page\n",
    "    nextPage = response.json()['paging']['next']\n",
    "    \n",
    "    #to avoid getting ip banned, we wait for a bit\n",
    "    #waiting is randomly between 1 and 3 seconds to simulate\n",
    "    #some sort of natural traffic\n",
    "    time.sleep(random.random()*2 + 1)\n",
    "    print('We have done ' + str(j*500 + 500) + ' requests')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "25fac7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#write to a file\n",
    "anime_list = open(\"anime_list_details.json\", 'w')\n",
    "anime_list.write(json.dumps(data))\n",
    "anime_list.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "f67d681f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################\n",
    "## Getting user data                    ##\n",
    "##########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "6e670ea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Have retrieved 1008 usernames\n",
      "Have retrieved 2016 usernames\n",
      "Have retrieved 3000 usernames\n",
      "Have retrieved 4008 usernames\n",
      "Have retrieved 5015 usernames\n",
      "Have retrieved 6023 usernames\n",
      "Have retrieved 7007 usernames\n",
      "Have retrieved 8015 usernames\n",
      "Have retrieved 9023 usernames\n",
      "Have retrieved 10007 usernames\n",
      "Have retrieved 11015 usernames\n",
      "Have retrieved 12023 usernames\n",
      "Have retrieved 13007 usernames\n",
      "Have retrieved 14015 usernames\n",
      "Have retrieved 15023 usernames\n",
      "Have retrieved 16007 usernames\n",
      "Have retrieved 17015 usernames\n",
      "Have retrieved 18023 usernames\n",
      "Have retrieved 19007 usernames\n",
      "Have retrieved 20015 usernames\n",
      "Have retrieved 21023 usernames\n",
      "Have retrieved 22007 usernames\n",
      "Have retrieved 23015 usernames\n",
      "Have retrieved 24023 usernames\n",
      "Have retrieved 25007 usernames\n",
      "Have retrieved 26015 usernames\n",
      "Have retrieved 27023 usernames\n",
      "Have retrieved 28007 usernames\n",
      "Have retrieved 29015 usernames\n",
      "Have retrieved 30023 usernames\n",
      "Have retrieved 31007 usernames\n",
      "Have retrieved 32015 usernames\n",
      "Have retrieved 33023 usernames\n",
      "Have retrieved 34007 usernames\n",
      "Have retrieved 35015 usernames\n",
      "Have retrieved 36023 usernames\n",
      "Have retrieved 37007 usernames\n",
      "Have retrieved 38015 usernames\n",
      "Have retrieved 39023 usernames\n",
      "Have retrieved 40007 usernames\n",
      "Have retrieved 41015 usernames\n",
      "Have retrieved 42023 usernames\n",
      "Have retrieved 43007 usernames\n",
      "Have retrieved 44015 usernames\n",
      "Have retrieved 45023 usernames\n",
      "Have retrieved 46007 usernames\n",
      "Have retrieved 47015 usernames\n",
      "Have retrieved 48022 usernames\n",
      "Have retrieved 49006 usernames\n",
      "Have retrieved 50014 usernames\n",
      "Have retrieved 51022 usernames\n",
      "Have retrieved 52006 usernames\n",
      "Have retrieved 53014 usernames\n",
      "Have retrieved 54022 usernames\n",
      "Have retrieved 55006 usernames\n",
      "Have retrieved 56014 usernames\n",
      "Have retrieved 57022 usernames\n",
      "Have retrieved 58006 usernames\n",
      "Have retrieved 59014 usernames\n",
      "Have retrieved 60022 usernames\n",
      "Have retrieved 61006 usernames\n",
      "Have retrieved 62014 usernames\n",
      "Have retrieved 63022 usernames\n",
      "Have retrieved 64006 usernames\n",
      "Have retrieved 65014 usernames\n",
      "Have retrieved 66022 usernames\n",
      "Have retrieved 67006 usernames\n",
      "Have retrieved 68014 usernames\n",
      "Have retrieved 69022 usernames\n",
      "Have retrieved 70006 usernames\n",
      "Have retrieved 71014 usernames\n",
      "Have retrieved 72022 usernames\n",
      "Have retrieved 73006 usernames\n",
      "Have retrieved 74014 usernames\n",
      "Have retrieved 75022 usernames\n",
      "Have retrieved 76006 usernames\n",
      "Have retrieved 77014 usernames\n",
      "Have retrieved 78022 usernames\n",
      "Have retrieved 79006 usernames\n",
      "Have retrieved 80014 usernames\n",
      "Have retrieved 81022 usernames\n",
      "Have retrieved 82006 usernames\n",
      "Have retrieved 83014 usernames\n",
      "Have retrieved 84022 usernames\n",
      "Have retrieved 85006 usernames\n",
      "Have retrieved 86014 usernames\n",
      "Have retrieved 87022 usernames\n",
      "Have retrieved 88006 usernames\n",
      "Have retrieved 89014 usernames\n",
      "Have retrieved 90022 usernames\n",
      "Have retrieved 91006 usernames\n",
      "Have retrieved 92014 usernames\n",
      "Have retrieved 93022 usernames\n",
      "Have retrieved 94006 usernames\n",
      "Have retrieved 95014 usernames\n",
      "Have retrieved 96022 usernames\n",
      "Have retrieved 97006 usernames\n",
      "Have retrieved 98014 usernames\n",
      "Have retrieved 99022 usernames\n",
      "Have retrieved 100006 usernames\n"
     ]
    }
   ],
   "source": [
    "#okay, now we want to just get a list of users, and we cannot do this through any API\n",
    "#some experimenting, this gets the users between 1 and 122, which for all intents and purposes, is everyone\n",
    "#the oldest recorded person is 122\n",
    "baseURL = \"https://myanimelist.net/users.php?\"\n",
    "para = {\n",
    "    \"cat\":\"user\",\n",
    "    \"q\":\"\",\n",
    "    \"loc\":\"\",\n",
    "    \"agelow\":\"1\",\n",
    "    \"agehigh\":\"122\",\n",
    "    \"show\":0,\n",
    "}\n",
    "numberOfUsernamesGoal = 100000\n",
    "\n",
    "users = []\n",
    "\n",
    "response = requests.get(baseURL, params=para)\n",
    "#we keep going as long as we are getting okay status codes, we can always start again\n",
    "while(response.status_code == 200 and len(users) < numberOfUsernamesGoal):\n",
    "    foundUsernames = getUsernames(response.text)\n",
    "    users += foundUsernames\n",
    "    para['show'] += 24\n",
    "    \n",
    "    if(len(users) % 1000 < 24):\n",
    "        print('Have retrieved ' + str(len(users)) + ' usernames')\n",
    "    \n",
    "    #to avoid getting ip banned, we wait for a bit\n",
    "    #waiting is randomly between 1 and 3 seconds to simulate\n",
    "    #some sort of natural traffic\n",
    "    time.sleep(random.random()*2 + 1)\n",
    "    \n",
    "    #now let's make the request\n",
    "    response = requests.get(baseURL, params=para)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "a2079f97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100006"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "26f6a507",
   "metadata": {},
   "outputs": [],
   "source": [
    "#write to a file\n",
    "user_list = open(\"username_list.txt\", 'w')\n",
    "user_list.write(json.dumps(users))\n",
    "user_list.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "074f1321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting details on user's animelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "3bac48ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, we get our users\n",
    "user_file = open(\"username_list.txt\", 'r')\n",
    "usernames = json.load(user_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "e757a5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "count = 0 #this is here so we can keep track of how many usernames we've gone through and keep going in case of an error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "fcb7758b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Have retrieved animelists for 51001 users\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "[Errno Expecting value] <!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01 Transitional//EN\" \"http://www.w3.org/TR/html4/loose.dtd\">\n<HTML><HEAD><META HTTP-EQUIV=\"Content-Type\" CONTENT=\"text/html; charset=iso-8859-1\">\n<TITLE>ERROR: The request could not be satisfied</TITLE>\n</HEAD><BODY>\n<H1>403 ERROR</H1>\n<H2>The request could not be satisfied.</H2>\n<HR noshade size=\"1px\">\nRequest blocked.\nWe can't connect to the server for this app or website at this time. There might be too much traffic or a configuration error. Try again later, or contact the app or website owner.\n<BR clear=\"all\">\nIf you provide content to customers through CloudFront, you can find steps to troubleshoot and help prevent this error by reviewing the CloudFront documentation.\n<BR clear=\"all\">\n<HR noshade size=\"1px\">\n<PRE>\nGenerated by cloudfront (CloudFront)\nRequest ID: 1NTPLxFZzcxqP5sTiwgJ2xmHChBoJyhjuuQHhB2sGizyxP-XQIEGRA==\n</PRE>\n<ADDRESS>\n</ADDRESS>\n</BODY></HTML>: 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\models.py:910\u001b[0m, in \u001b[0;36mResponse.json\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    909\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 910\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m complexjson\u001b[38;5;241m.\u001b[39mloads(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    911\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    912\u001b[0m     \u001b[38;5;66;03m# Catch JSON-related errors and raise as requests.JSONDecodeError\u001b[39;00m\n\u001b[0;32m    913\u001b[0m     \u001b[38;5;66;03m# This aliases json.JSONDecodeError and simplejson.JSONDecodeError\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\json\\__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[1;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\json\\decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;124;03mcontaining a JSON document).\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[0;32m    336\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 337\u001b[0m obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    338\u001b[0m end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\json\\decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Input \u001b[1;32mIn [298]\u001b[0m, in \u001b[0;36m<cell line: 14>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(baseURL\u001b[38;5;241m+\u001b[39musername\u001b[38;5;241m+\u001b[39mappendURL, params\u001b[38;5;241m=\u001b[39mpara, headers\u001b[38;5;241m=\u001b[39mhead)    \n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m#if user has a private list or there is some other error accessing the list, we skip\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m):\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m     22\u001b[0m response_data \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mjson()[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\models.py:917\u001b[0m, in \u001b[0;36mResponse.json\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    915\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RequestsJSONDecodeError(e\u001b[38;5;241m.\u001b[39mmessage)\n\u001b[0;32m    916\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 917\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RequestsJSONDecodeError(e\u001b[38;5;241m.\u001b[39mmsg, e\u001b[38;5;241m.\u001b[39mdoc, e\u001b[38;5;241m.\u001b[39mpos)\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: [Errno Expecting value] <!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01 Transitional//EN\" \"http://www.w3.org/TR/html4/loose.dtd\">\n<HTML><HEAD><META HTTP-EQUIV=\"Content-Type\" CONTENT=\"text/html; charset=iso-8859-1\">\n<TITLE>ERROR: The request could not be satisfied</TITLE>\n</HEAD><BODY>\n<H1>403 ERROR</H1>\n<H2>The request could not be satisfied.</H2>\n<HR noshade size=\"1px\">\nRequest blocked.\nWe can't connect to the server for this app or website at this time. There might be too much traffic or a configuration error. Try again later, or contact the app or website owner.\n<BR clear=\"all\">\nIf you provide content to customers through CloudFront, you can find steps to troubleshoot and help prevent this error by reviewing the CloudFront documentation.\n<BR clear=\"all\">\n<HR noshade size=\"1px\">\n<PRE>\nGenerated by cloudfront (CloudFront)\nRequest ID: 1NTPLxFZzcxqP5sTiwgJ2xmHChBoJyhjuuQHhB2sGizyxP-XQIEGRA==\n</PRE>\n<ADDRESS>\n</ADDRESS>\n</BODY></HTML>: 0"
     ]
    }
   ],
   "source": [
    "# This should be just an array of usernames\n",
    "# for each username, we will enter it into our data dict\n",
    "\n",
    "baseURL = \"https://api.myanimelist.net/v2/users/\"\n",
    "appendURL = \"/animelist?\"\n",
    "para = {\n",
    "    \"fields\":\"list_status,start_date,end_date,id\",\n",
    "    \"limit\":1000,\n",
    "    \"offset\":0,\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "for username in usernames[count-1:]:\n",
    "    count += 1\n",
    "    response = requests.get(baseURL+username+appendURL, params=para, headers=head)    \n",
    "    \n",
    "    #if user has a private list or there is some other error accessing the list, we skip\n",
    "    if('error' in response.json()):\n",
    "        continue\n",
    "        \n",
    "    response_data = response.json()['data']\n",
    "\n",
    "        \n",
    "    #sanity check print statements\n",
    "    if(count % 1000 == 1):\n",
    "        print('Have retrieved animelists for ' + str(count) + ' users')\n",
    "        \n",
    "    #if something happens let's stop\n",
    "    if(response.status_code != 200):\n",
    "        print('Got HTTP status code: ' + str(response.status_code) + ', exiting now.')\n",
    "        break\n",
    "    \n",
    "    #to avoid getting ip banned or rate limited, we wait 270ms\n",
    "    time.sleep(0.27)\n",
    "    \n",
    "    #storing JSON is too big. let's put it in a csv.\n",
    "    #we are really just storing the list as an array with csv values\n",
    "    #user,id,start_date,end_date,score,num_episodes_watched,status\n",
    "    #status encoding: watching = 0, completed = 1, on_hold = 2, dropped = 3, plan_to_watch = 4\n",
    "\n",
    "    for entry in response_data:\n",
    "        data.append(str(username) + ',' + str(entry['node']['id']) + ',' + str(getCSVDates(entry['list_status'])) + ',' + str(entry['list_status']['score']) + ',' + str(entry['list_status']['num_episodes_watched']) + ',' + str(getStatusEncoding(entry['list_status'].get('status'))))\n",
    "    \n",
    "    #if there are more than 1000 entries, we need to keep going through pages\n",
    "    while('next' in response.json()['paging']):\n",
    "        response = requests.get(response.json()['paging']['next'], headers=head)\n",
    "        response_data = response.json()['data']\n",
    "        for entry in response_data:\n",
    "            data.append(str(username) + ',' + str(entry['node']['id']) + ',' + str(getCSVDates(entry['list_status'])) + ',' + str(entry['list_status']['score']) + ',' + str(entry['list_status']['num_episodes_watched']) + ',' + str(getStatusEncoding(entry['list_status'].get('status'))))\n",
    "        time.sleep(0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2f8c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79574bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#start date and end date could be absent from the list status.\n",
    "#this function returns strings correctly for the csv for both of them\n",
    "def getCSVDates(list_status):\n",
    "    start_date_csv = \"\"\n",
    "    if('start_date' not in list_status):\n",
    "        start_date_csv = \",\"\n",
    "    else:\n",
    "        start_date_csv = list_status['start_date'] + ','\n",
    "        \n",
    "    end_date_csv = \"\"\n",
    "    if('finish_date' not in list_status):\n",
    "        end_date_csv = \"\"\n",
    "    else:\n",
    "        end_date_csv = list_status['finish_date'] \n",
    "        \n",
    "    return start_date_csv + end_date_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8b36fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getStatusEncoding(status):\n",
    "    if status == 'watching':\n",
    "        return 0\n",
    "    if status == 'completed':\n",
    "        return 1\n",
    "    if status == 'on_hold':\n",
    "        return 2\n",
    "    if status == 'dropped':\n",
    "        return 3\n",
    "    if status == 'plan_to_watch':\n",
    "        return 4\n",
    "    return 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "a9b252cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8762677"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "8e7c4521",
   "metadata": {},
   "outputs": [],
   "source": [
    "#write to a file\n",
    "user_list = open(\"user_animelist_details.txt\", 'w',encoding='utf-8')\n",
    "for i in data:\n",
    "    user_list.write(i+'\\n')\n",
    "user_list.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7e7a77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "815f8a88451bb9ed6445b8cdfafbc21867b1e3069831021276f9d3e049931616"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
